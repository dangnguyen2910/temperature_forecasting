{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import pmdarima.arima\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2023-10-01    18.9\n",
       "2023-10-02    20.7\n",
       "2023-10-03    18.8\n",
       "2023-10-04    14.2\n",
       "2023-10-05    14.7\n",
       "2023-10-06    14.7\n",
       "2023-10-07    16.7\n",
       "2023-10-08    18.5\n",
       "2023-10-09    18.9\n",
       "2023-10-10    18.9\n",
       "Name: temp, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/paris_temperature.csv')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.set_index(df['datetime'])\n",
    "temp = df['temp']\n",
    "temp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(ts):\n",
    "    adf_result = adfuller(ts)\n",
    "\n",
    "    # Output the results\n",
    "    print('ADF Statistic:', adf_result[0])\n",
    "    print('p-value:', adf_result[1])\n",
    "        \n",
    "    if adf_result[1] < 0.05:\n",
    "        print(\"Time series is stationary.\")\n",
    "    else:\n",
    "        print(\"Time series is non-stationary.\")\n",
    "\n",
    "adf_test(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_temp = seasonal_decompose(temp, model='additive')\n",
    "\n",
    "res_temp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# Plot ACF and PACF\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "pd.plotting.autocorrelation_plot(temp)\n",
    "\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "plot_pacf(temp,ax = ax, method='ywm', lags=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Differencing order: {ndiffs(temp, test='adf')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10-08</th>\n",
       "      <td>18.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-10</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-12</th>\n",
       "      <td>19.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  lag1  lag2  lag3  lag4  lag5  lag6  lag7\n",
       "datetime                                                    \n",
       "2023-10-08    18.5  16.7  14.7  14.7  14.2  18.8  20.7  18.9\n",
       "2023-10-09    18.9  18.5  16.7  14.7  14.7  14.2  18.8  20.7\n",
       "2023-10-10    18.9  18.9  18.5  16.7  14.7  14.7  14.2  18.8\n",
       "2023-10-11    18.9  18.9  18.9  18.5  16.7  14.7  14.7  14.2\n",
       "2023-10-12    19.0  18.9  18.9  18.9  18.5  16.7  14.7  14.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lag_embedding(ts, lags):\n",
    "    ts_lag = pd.DataFrame({'target':ts})\n",
    "        \n",
    "    for i in range(lags):\n",
    "        shift_ts = ts.shift(i+1).rename(f\"lag{i+1}\")\n",
    "        ts_lag = pd.concat([ts_lag, shift_ts], axis=1)\n",
    "\n",
    "    ts_lag = ts_lag.dropna()\n",
    "\n",
    "    return ts_lag\n",
    "\n",
    "temp_lag = lag_embedding(temp, lags=7)\n",
    "temp_lag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = temp_lag[temp_lag.index <= pd.to_datetime('2024/09/15')]\n",
    "test = temp_lag[temp_lag.index > pd.to_datetime('2024/09/15')]\n",
    "\n",
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "plt.plot(train['target'], label='Train')\n",
    "plt.plot(test['target'], label='Test')\n",
    "plt.gca().xaxis.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_normalized = scaler.transform(train)\n",
    "# test_normalized = scaler.transform(test)\n",
    "\n",
    "min_temp = train.min(axis=None)\n",
    "max_temp = train.max(axis=None)\n",
    "\n",
    "def min_max_scaler(x):\n",
    "    return (x - min_temp) / (max_temp - min_temp)\n",
    "\n",
    "train_normalized = train.map(min_max_scaler).values\n",
    "test_normalized = test.map(min_max_scaler).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParisTemperatureTimeDelayEmbedding(Dataset):\n",
    "    def __init__(self,  dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        features = self.dataset[idx, 1:]\n",
    "        target = self.dataset[idx, 0]\n",
    "\n",
    "        features = torch.from_numpy(np.asarray(features)).float()\n",
    "        target = torch.from_numpy(np.asarray(target)).float()\n",
    "        return features, target\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ParisTemperatureTimeDelayEmbedding(train_normalized)\n",
    "test_dataset = ParisTemperatureTimeDelayEmbedding(test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmOneHorizon(nn.Module):\n",
    "    def __init__(self,hidden_size1 = 32, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size = 1, hidden_size= hidden_size1, num_layers=num_layers, batch_first=True)\n",
    "        self.regressor = nn.Linear(in_features=hidden_size1, out_features=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (x, _) = self.lstm1(x)\n",
    "        if (x.size(0) != 1):\n",
    "            x = self.flatten(x)\n",
    "        x = self.regressor(x)\n",
    "\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "\n",
    "model = LstmOneHorizon(hidden_size1=32).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "best_test_loss = 10000\n",
    "\n",
    "print(f\"Lags: {lags}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('-' * 100)\n",
    "    print(f'EPOCH [{epoch+1}/{epochs}]')\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    loss_train_batch = 0 \n",
    "    for i, (features, target) in enumerate(train_dataloader):\n",
    "        features = features.to(device).unsqueeze(2)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features)\n",
    "\n",
    "        # In case batch only has 1 sample, output will be of shape []\n",
    "        # The below \"if\" is to transform shape to [1] to make it comparable with \n",
    "        # the target\n",
    "        if (output.size() == torch.Size([])):\n",
    "            output = output.unsqueeze(0)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch += loss.item()\n",
    "    \n",
    "    train_loss.append(loss_train_batch/len(train_dataloader))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    loss_val_batch = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (features, target) in enumerate(test_dataloader):\n",
    "            features = features.to(device).unsqueeze(2)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(features)\n",
    "\n",
    "            # In case batch only has 1 sample, output will be of shape []\n",
    "            # The below \"if\" is to transform shape to [1] to make it comparable with \n",
    "            # the target\n",
    "            if (output.size() == torch.Size([])):\n",
    "                output = output.unsqueeze(0)\n",
    "    \n",
    "            vloss = loss_fn(output, target)\n",
    "\n",
    "            loss_val_batch += vloss.item()\n",
    "\n",
    "    test_loss.append(loss_val_batch/len(test_dataloader))\n",
    "    print(f'Train loss: {loss_train_batch/len(train_dataloader)}, Validation loss: {loss_val_batch/len(test_dataloader)}')\n",
    "\n",
    "    if (loss_val_batch < best_test_loss):\n",
    "        best_test_loss = loss_val_batch\n",
    "        print(\"New best model found\")\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(np.arange(len(train_loss), dtype=int), train_loss, label='train')\n",
    "plt.plot(np.arange(len(test_loss), dtype=int), test_loss, label= 'validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LstmOneHorizon().to(device)\n",
    "# model.load_state_dict(torch.load('../model/temp_norm_lstm_ts1_b16.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs = []\n",
    "test_outputs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (features, target) in enumerate(train_dataloader):\n",
    "        features = features.to(device).unsqueeze(2)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        # In case batch only has 1 sample, output will be of shape []\n",
    "        # The below \"if\" is to transform shape to [1] to make it comparable with \n",
    "        # the target\n",
    "        if (output.size() == torch.Size([])):\n",
    "            output = output.unsqueeze(0)\n",
    "        output = output.cpu().tolist()\n",
    "\n",
    "        train_outputs += output\n",
    "        \n",
    "\n",
    "    for i, (features, target) in enumerate(test_dataloader):\n",
    "        features = features.to(device).unsqueeze(2)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(features)\n",
    "\n",
    "        # In case batch only has 1 sample, output will be of shape []\n",
    "        # The below \"if\" is to transform shape to [1] to make it comparable with \n",
    "        # the target\n",
    "        if (output.size() == torch.Size([])):\n",
    "            output = output.unsqueeze(0)\n",
    "\n",
    "        output = output.cpu().tolist()\n",
    "\n",
    "        test_outputs += output\n",
    "\n",
    "train_outputs = np.array(train_outputs)\n",
    "test_outputs = np.array(test_outputs)\n",
    "\n",
    "train_outputs = train_outputs * (max_temp - min_temp) + min_temp\n",
    "test_outputs = test_outputs * (max_temp - min_temp) + min_temp\n",
    "\n",
    "train_outputs = pd.Series(np.squeeze(train_outputs), index=train.index)\n",
    "test_outputs = pd.Series(np.squeeze(test_outputs), index=test.index)\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.plot(train['target'], label='Train truth', color='blue')\n",
    "plt.plot(train_outputs,color='crimson', linestyle = 'dashed', label='Train pred')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.plot(test['target'], color='green', label='Val truth', marker='.')\n",
    "plt.plot(test_outputs,color = 'crimson', linestyle = 'dashed',marker='.', label='Val pred')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE = {root_mean_squared_error(test['target'], test_outputs)}\")\n",
    "print(f\"R2 = {r2_score(test['target'], test_outputs)}\")\n",
    "print(f\"MAPE = {mean_absolute_percentage_error(test['target'], test_outputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'../model/temp_norm_Lstm_ts{lags}_b{batch}_nl{num_layers}_.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_embedding(trial, ts):\n",
    "    lags = trial.suggest_int('lags', 1, 30)\n",
    "    ts_lag = pd.DataFrame({'target':ts})\n",
    "        \n",
    "    for i in range(lags):\n",
    "        shift_ts = ts.shift(i+1).rename(f\"lag{i+1}\")\n",
    "        ts_lag = pd.concat([ts_lag, shift_ts], axis=1)\n",
    "\n",
    "    ts_lag = ts_lag.dropna()\n",
    "\n",
    "    return ts_lag\n",
    "\n",
    "\n",
    "def split_train_test(ts, date='2024/09/15'):\n",
    "    train = ts[ts.index <= pd.to_datetime(date)]\n",
    "    test = ts[ts.index > pd.to_datetime(date)]\n",
    "\n",
    "    return train, test\n",
    "    \n",
    "def normalize(train, test):\n",
    "    min_ts = train.min(axis=None)\n",
    "    max_ts = train.max(axis=None)\n",
    "\n",
    "    def min_max_scaler(x):\n",
    "        return (x - min_ts) / (max_ts - min_ts)\n",
    "    \n",
    "\n",
    "    train_normalized = train.map(lambda x: (x - min_ts)/(max_ts - min_ts)).values\n",
    "    test_normalized = test.map(lambda x: (x - min_ts)/(max_ts - min_ts)).values\n",
    "    \n",
    "    return train_normalized, test_normalized, min_ts, max_ts\n",
    "\n",
    "def get_dataloader(trial, train, test):\n",
    "    batch = trial.suggest_int('batch_size', 8, 32)\n",
    "\n",
    "    train_dataset = ParisTemperatureTimeDelayEmbedding(train)\n",
    "    test_dataset = ParisTemperatureTimeDelayEmbedding(test)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def define_model(trial):\n",
    "    hidden_size1 = trial.suggest_int(\"hidden_size1\", 32, 256)\n",
    "    model = LstmOneHorizon(hidden_size1=hidden_size1)\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    temp_lag = lag_embedding(trial, temp, )\n",
    "    train, test = split_train_test(temp_lag)\n",
    "    train_normalized, test_normalized, min, max = normalize(train, test)\n",
    "    train_dataloader, test_dataloader = get_dataloader(trial, train_normalized, test_normalized)\n",
    "\n",
    "    model = define_model(trial).to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 0.00001, 0.001, log=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.00001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "\n",
    "    epochs = 1000\n",
    "    train_loss = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_train_batch = 0 \n",
    "        for i, (features, target) in enumerate(train_dataloader):\n",
    "            features = features.to(device).unsqueeze(2)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "\n",
    "            if (output.size() == torch.Size([])):\n",
    "                output = output.unsqueeze(0)\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train_batch += loss.item()\n",
    "        \n",
    "        train_loss.append(loss_train_batch/len(train_dataloader))\n",
    "\n",
    "        test_outputs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (features, target) in enumerate(test_dataloader):\n",
    "                features = features.to(device).unsqueeze(2)\n",
    "                target = target.to(device)\n",
    "\n",
    "                output = model(features)\n",
    "\n",
    "                if (output.size() == torch.Size([])):\n",
    "                    output = output.unsqueeze(0)\n",
    "\n",
    "                output = output.cpu().tolist()\n",
    "\n",
    "                test_outputs += output\n",
    "\n",
    "        test_outputs = np.array(test_outputs)\n",
    "        test_outputs = test_outputs * (max - min) + min\n",
    "        test_outputs = pd.Series(np.squeeze(test_outputs), index=test.index)\n",
    "\n",
    "        rmse = root_mean_squared_error(test['target'], test_outputs)\n",
    "        trial.report(rmse, epoch) \n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_trial.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = test['target'] - test_outputs \n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "fig.add_subplot(3,2,1)\n",
    "plt.axhline(0, color='k', linestyle='dashed')\n",
    "plt.plot(residuals, '.')\n",
    "plt.title(\"Residual vs time\")\n",
    "\n",
    "fig.add_subplot(3,2,2)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "\n",
    "ax = fig.add_subplot(3,2,3)\n",
    "plot_acf(residuals, lags=20, ax=ax, zero=False)\n",
    "\n",
    "fig.add_subplot(3,2,4)\n",
    "plt.scatter(test_outputs, residuals)\n",
    "plt.title(\"Residual vs ground truth\")\n",
    "\n",
    "fig.add_subplot(3,2,5)\n",
    "plt.boxplot(residuals, vert=False)\n",
    "plt.title(\"Residual box plot\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(residuals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
